# Replier bots

Se ha hablado de que uno de los procedimientos de composición de este proyecto de literatura electrónica es la expansión de las narrativas preexistentes de las noticias falsas. Ello se ha realizado a partir de intercambios en el eje paradigmático de las informaciones que han sido clasificadas como falsas por los fact checkers hispanoamericanos agrupados en la iniciativa Latam Chequea. De ese modo, donde se encontraba en el texto original el nombre 'Bill Gates' se ha intercambiado en el texto generado por el nombre de algún otro empresario entre los más adinerados a nivel global. Tal es, en resumidas cuentas, el procedimiento central del Generador de Teorías de Conspiración y del Generador de Recetas de Curas Milagrosas. Para más información, En esta ocasión, se ha buscado explorar el procedimiento de expansión narrativa desde una perspectiva distinta.

# ¿Qué son los replier bots?

Los replier bots (o bots replicadores) son pequeños programas informáticos creados con la herramienta disponible en línea Cheap Bots Done Quick, la cual, con una codificación simple, permite crear una gran cantidad de textos a partir de combinar componentes textuales de forma aleatoria y siguiendo un ordenamiento lingüístico  prefijado. Estos textos deberán cumplir con la extensión de 280 caracteres debido a que los bots son creados con la herramienta para que operen en Twitter. En el caso de este proyecto, se busca hacer uso de esta herramienta con fines literarios. De ese modo, estos replier bots tienen como objetivo compartir y comentar los textos que producen estos generadores (es decir, 'responder' a los tuits producidos por estos generadores, que se encuentran también como entidades en Twitter bajo sus mismos nombres -Generador de Teorías de Conspiración y Generador de Recetas de Curas Milagrosas-). Desde el punto de vista literario, con ello se busca sumar otro nivel a la expansión de los relatos de las noticias falsas: estos no solo serán expandidos por los generadores, sino que también serán compartidos y comentados por los replier bots. Con ello, estos textos generados de forma anónima son compartidos por entidades digitales con nombre y apellido, y foto de perfil. Es decir, pasan a ser parte de una conversación digital que estas entidades no anónimas, que cuentan con los datos básicos de perfil como los usuarios humanos, forman con sus seguidores.

Este procedimiento de crear una conversación entre entidades digitales forma parte del objetivo central del proyecto de Contenido Manipulado, que es el de imitar las dinámicas de producción y distribución de la desinformación. Este grupo de bots compartirán los tuits de los generadores en sus perfiles personales, con lo cual los textos producidos por entidades anónimas pasarán a habitar el historial de publicaciones de entidades con nombre y apellido, y foto; es decir, que emulan ser personas reales. Con ello estas supuestas personas esparcen estos textos literarios que imitan a las noticias falsas, de la misma manera que los usuarios de redes sociales esparcen las noticias falsas reales. 

Por otro lado, este procedimiento no es solo de distribución, sino también de producción, debido a que los textos que escribirán estos bots son diferentes a aquellos de los generadores. Es más, se busca que los comentarios de los bots guarden, en primer lugar, una relación lógica con el mensaje comentado: se buscará simular que el comentario nace de una reflexión o de un procesamiento del contenido del texto de los generadores, con lo cual se dibuja un razonamiento coherente entre ambas distintas publicaciones. En segundo lugar, se busca trazar una relación sintáctica entre las dos publicaciones, ya que el replier bot aludirá mediante frases o referentes (como 'esto', 'este', 'esta publicación', etc.) directamente a los textos de los generadores. De esta manera se busca producir un encadenamiento coherente y cohesionado entre el texto nuevo del bot y el texto producido con anterioridad por los generadores.  

# Sobre nombres, imágenes y heterónimos

Como se ha planteado, este proyecto busca ir más allá de la producción de textos que sean simulaciones de noticias falsas, y desarrollar también identidades digitales que imiten identidades de personas reales que compartan información falsa. A fin de lograr verosimilitud, se busca trazar al menos un boceto de lo que sería identidad digital con características específicas. Ello para que se procesen e interpreten estas supuestas informaciones falsas desde un lugar específico de enunciación.

Lo más evidente son los datos de perfil. Estos bots tienen nombres ficticios. En realidad, son nombres extraídos de autores ficticios creados por el escritor portugués Fernando Pessoa (1888-1935), quien creó lo que los críticos llaman heterónimos. Ello quiere decir que no solo utilizó su nombre para publicar sus textos, sino también otros; sin embargo, no se trata solo de la práctica de la adopción de seudónimos, sino de la creación de identidades autoriales ficticias, cuya existencia en el mundo real se constata solamente con la escritura y firma de sus obras. Es más, estas identidades son independientes entre sí, y como tales desarrollan temas propios, tienen visiones del mundo distintas al igual que registros lingüísticos específicos, y son artífices de géneros o subgéneros distintos entre ellas. Es decir, no se trata de enmascarar al mismo autor bajo otro nombre, sino de crear otros autores que se propongan como independientes del autor que tiene existencia más allá del texto.      
Según el crítico Jerónimo Pizarro, Pessoa creó 136 heterónimos. De ellos, son cuatro los que alcanzaron mayor notoriedad. Ello porque estos conforman lo que sería el canon de la obra de Pessoa, que es variada y extensa. Se trata de Ricardo Reis, Alvaro de Campos, Alberto Caeiro y Bernardo Soares. Y para nombrar a los bots se han mezclado los nombres y apellidos de estos cuatro autores. Es por ello que uno de los bots se llama Ricardo Cairo y otro Bernardo de Campos. 

Además del nombre, se agrega una foto. Ya que se trata de una entidad ficcional, la foto ha sido tomada del sitio This Person Doesn't Exist (https://thispersondoesnotexist.com/), que, como su nombre lo indica, genera imágenes de personas que no existen. Este sitio web, para producir tales imágenes trabaja con redes generativas adversarias (GAN, generative adversarial networks en inglés), que es una clase de machine learning en la cual dos redes neuronales trabajan de forma conjunta para generar imágenes realistas, en una dinámica en la cual una red propone candidatas de imágenes y la otra las evalúa como realistas o no realistas. Para comenzar a funcionar, se trabaja con un conjunto de datos que servirán de base para la posterior producción generativa de las redes.  
Ello podría tener cierta lógica interna: a un autor cuyos únicos indicios de existencia son los textos que produce se le asigna la foto de una persona que no existe, que habita el entorno digital a partir de una sola imagen. Al fin y al cabo, esos dos componentes pueden ser los más relevantes para identificar a una persona en una red social como Twitter: una imagen de perfil, que estabilice sus rasgos físicos propios ante la plataforma misma y los otros usuarios, y publicaciones periódicas que den cuenta de los eventos de su vida, sus pensamientos, sus relaciones sociales, entre otros. En otras palabras, una imagen que sea prueba de los rasgos físicos que son propios de él/ella y una narrativa de quien es -que también ha de ser propia-. Del mismo modo, tanto la producción de textos por parte del bot como de la imagen son, a pesar de la mayor complejidad técnica de This Person Doesnt Exist, de naturaleza algorítmica, lo que podria agregar algún otro nivel de coherencia interna a las piezas de literatura digital.       

# Identidades autoriales

En el artículo “The Bot Politic” de Jacqueline Feldman (https://www.newyorker.com/tech/annals-of-technology/the-bot-politic), la autora comenta su experiencia en el desarrollo de un chatbot llamado Kai encargado de guiar a los usuarios en trámites bancarios. Específicamente, a Feldman, quien trabaja con inteligencia artificial se le ha pedido desarrollar la personalidad del chatbot. Esto resulta para ella aterrador en un primer momento, debido a que siente que puede escribir de forma regular diálogos pero que la palabra misma personalidad contiene la categoría 'persona' en ella: "My contract bound me to create a ‘personality,’ which sounded like more than the sum of its parts, and also has the word ‘person’ built into it" (2016). Se trata de una personalidad, pero Kai, comenta la autora, tiene que cumplir solventemente sus funciones, por lo cual tiene que ser "friendly but authoritative, engaging but not creepy" (2016), además de que, a diferencia de una persona, no puede abandonar la comunicación. Resulta interesante apreciar cómo se va diseñando la persoanlidad para una entidad digital, que en este caso debe ser funcional para cubrir sus tareas y, sin embargo, Feldman agrega algunas características propias a Kai que se pueden entender como identitarias, propias de Kai y no de algún otro chatbot que tenga que cumplir funciones similares: "I decided that I would write Kai as a magpie for idioms, puns, and encyclopedic facts, and that it would frame them in its own way, like an entity new to Planet Human" (2016). Incluso con un sentido del humor que se podría considerar particular. Una broma que generó Kai es la siguiente: "Humans save their money for a rainy day but don’t spend more when it rains" (2016).

Con el trabajo que programadores como Feldman desarrollan para entidades digitales, sumado a la revisión de una de las mayores particulares creativas de la obra de Pessoa, se estableció una idea relevante para este proyecto de literatura electrónica: la creación de entidades autoriales digitales con rasgos personales como procedimiento literario. Es decir, se busca trasladar la creación de entidades autoriales ficticias, los heterónimos de Pessoa, al terreno digital y aplicar este procedimiento a los bots de Twitter. Para este proyecto se buscará darle a cada uno de los bots si bien no una personalidad, porque eso sería algo muy complejo de conceptualizar y que demande mucho más tiempo del disponible para el trabajo, además de que posiblemente requiera habilidades técnicas especializadas en la programación, sí algunas características reconocibles. Estas serían unas determinadas áreas de interés sobre las cuales girarán sus publicaciones, un determinado tono de comunicación y, de ser posible, un registro lingüístico propio, al menos a grandes rasgos. Estos tres elementos estarán presentes en cada uno de sus tuits, y buscarán simular un sentido de personalidad para estas entidades digitales.  

# Reflexión final

El proyecto de los replier bots se inspira en el hecho de que la desinformación es esparcida por humanos y no humanos, y busca imitar esas dinámicas. De hecho, resulta en muchos casos muy complicado para el usuario común de redes sociales diferenciar a una entidad humana de una no humana. Ello no es fácil incluso para los investigadores de los campos de las ciencias de la computación, que han desarrollado estudios para caracterizar el comportamiento de estas entidades no humanas creadas con fines maliciosos y su impacto en colectividades humanas y en el mundo offline. 
En ese sentido, este proyecto busca emular el extenso y heterogéneo ecosistema de la desinformación en el entorno digital, que incluye, además de los creadores de noticias falsas, a usuarios consumidores de fake news, los cuales, a su vez, pueden ser distribuidores de las mismas. Para ello se han desarrollado distintos componentes que operen tanto en el plano de la producción como en el de la distribución. Y estos componentes son construidos sobre la base de frases fragmentarias que se permutan a partir de pequeños programas que permiten generar textos; es decir, la escritura tradicional se ve amplifica por los programas que permiten intercambiar frases como si fueran variables en una operación matemática. De este modo, la producción textual tiene una preponderante naturaleza algorítmica. Dicho esto, se busca, con la suma de las piezas que conforman Contenido Manipulado, desarrollar una literatura algorítmica que imite las dinámicas de una desinformación algorítmica, lo cual habría sido imposible con una escitura literaria no mediada por lo digital.
